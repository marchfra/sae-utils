parameters = {
    "latent_dim_factor": 8,
    "n_epochs": 250,
    "learning_rate": 1e-5,
    "activation": "topk",
    "k": 128,
    "threshold_iterations_dead_latent": 25_000,
    "alpha_aux_loss": 1.0 / 32.0,
    "k_aux": 256,
    "batch_size": 256,
}
